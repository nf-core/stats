---
title: "nf-core Pipeline Regulatory Compliance Report"
subtitle: "Quality Metrics and Development Tracking"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    theme: cosmo
    code-fold: true
    code-tools: true
    embed-resources: true
jupyter: python3
params:
  pipeline_name: "rnaseq"
---

```{python}
#| label: setup
#| include: false

# Import required libraries
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from pathlib import Path

# Set visualization style
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

# note: In Quarto Python, params are not directly accessible like in R?
pipeline_name = "rnaseq"

# Load data from JSON file (nested structure)
with open('data/stats.json', 'r') as f:
    stats_data = json.load(f)

# Convert nested structure to flat dataframe
pipeline_records = []
for pipeline_key, pipeline_data in stats_data.items():
    record = {}
    
    # Extract pipeline_stats
    if 'pipeline_stats' in pipeline_data and pipeline_data['pipeline_stats']:
        record.update(pipeline_data['pipeline_stats'])
    
    # Extract issue_stats
    if 'issue_stats' in pipeline_data and pipeline_data['issue_stats']:
        issue_stats = pipeline_data['issue_stats']
        record['issue_count'] = issue_stats.get('issue_count')
        record['closed_issue_count'] = issue_stats.get('closed_issue_count')
        record['median_seconds_to_issue_closed'] = issue_stats.get('median_seconds_to_issue_closed')
        record['pr_count'] = issue_stats.get('pr_count')
        record['closed_pr_count'] = issue_stats.get('closed_pr_count')
        record['median_seconds_to_pr_closed'] = issue_stats.get('median_seconds_to_pr_closed')
    
    # Extract contributor_stats
    if 'contributor_stats' in pipeline_data and pipeline_data['contributor_stats']:
        record['number_of_contributors'] = pipeline_data['contributor_stats'].get('number_of_contributors')
    
    pipeline_records.append(record)

pipelines_data = pd.DataFrame(pipeline_records)

# Convert date columns to datetime
date_columns = ['last_release_date']
for col in date_columns:
    if col in pipelines_data.columns:
        pipelines_data[col] = pd.to_datetime(pipelines_data[col], utc=True, errors='coerce')

# Add computed columns
pipelines_data['has_release'] = pipelines_data['last_release_date'].notna()

# Calculate status
def calculate_status(row):
    if row.get('archived', False):
        return 'Archived'
    elif not row.get('has_release', False):
        return 'In Development'
    else:
        if pd.notna(row['last_release_date']):
            days_since_release = (pd.Timestamp.now(tz='UTC') - row['last_release_date']).days
            if days_since_release < 180:
                return 'Active'
            elif days_since_release < 365:
                return 'Maintenance'
            else:
                return 'Legacy'
        else:
            return 'In Development'

pipelines_data['status'] = pipelines_data.apply(calculate_status, axis=1)

# Filter by pipeline if specified
if pipeline_name != "all":
    pipelines_data = pipelines_data[pipelines_data['name'] == pipeline_name]

if pipeline_name != "all" and pipeline_name in pipelines_data['name'].values:
    pipeline_info = pipelines_data[pipelines_data['name'] == pipeline_name].iloc[0]

# Store for later use
report_date = datetime.now().strftime("%B %d, %Y")
```


```{python}
#| echo: false
#| output: asis

print(f"**Report Period:** Could be based on first release \n")
print(f"**Pipeline:** {pipeline_name} \n")
print(f"**Description:** {pipeline_info['description']} \n")
print(f"**Last Release:** {pipeline_info['last_release_date']} \n")
```

This report provides regulatory-relevant metrics for nf-core pipelines, including:

- Pipeline version control and release history
- Development activity and maintenance status
- Community engagement and support responsiveness
- Quality assurance indicators
- Change management tracking

# Maintenance Metrics

## Issue and PR Resolution Metrics

```{python}
#| label: tbl-issues-summary
#| tbl-cap: "Issues and PR Resolution Metrics"
#| output: asis

# Get issue metrics (handle None values)
issue_count = pipeline_info.get('issue_count', 'N/A')
closed_issue_count = pipeline_info.get('closed_issue_count', 'N/A')
median_issue_close_time = pipeline_info.get('median_seconds_to_issue_closed')
median_issue_days = f"{median_issue_close_time / 86400:.1f}" if pd.notna(median_issue_close_time) else "N/A"

print(f"""
| Metric | Value | Notes |
|--------|-------|-------|
| Issues Count | {issue_count} | Total issues opened |
| Issues Closed | {closed_issue_count} | Issues that have been closed |
| Median Time to Issue Closure | {median_issue_days} days | Time from open to close |
""")
```



```{python}
#| label: tbl-pr-resolution-summary
#| tbl-cap: "Pull Request Resolution Metrics"
#| output: asis

# Get PR metrics (handle None values)
pr_count = pipeline_info.get('pr_count', 'N/A')
closed_pr_count = pipeline_info.get('closed_pr_count', 'N/A')
median_pr_close_time = pipeline_info.get('median_seconds_to_pr_closed')
median_pr_days = f"{median_pr_close_time / 86400:.1f}" if pd.notna(median_pr_close_time) else "N/A"

print(f"""
| Metric | Value | Notes |
|--------|-------|-------|
| Pull Request Count | {pr_count} | Total PRs opened |
| Pull Requests Closed | {closed_pr_count} | PRs that have been merged/closed |
| Median Time to PR Closure | {median_pr_days} days | Time from open to close |
""")
```

```{python}
#| label: fig-issue-pr-metrics
#| fig-cap: "Issue and Pull Request Activity"

import matplotlib.pyplot as plt
import numpy as np

# Extract metrics
issue_count = pipeline_info.get('issue_count', 0)
closed_issue_count = pipeline_info.get('closed_issue_count', 0)
pr_count = pipeline_info.get('pr_count', 0)
closed_pr_count = pipeline_info.get('closed_pr_count', 0)

# Handle None values
issue_count = issue_count if pd.notna(issue_count) else 0
closed_issue_count = closed_issue_count if pd.notna(closed_issue_count) else 0
pr_count = pr_count if pd.notna(pr_count) else 0
closed_pr_count = closed_pr_count if pd.notna(closed_pr_count) else 0

# Calculate open (unresolved) counts
open_issues = issue_count - closed_issue_count
open_prs = pr_count - closed_pr_count

# Create stacked bar chart
fig, ax = plt.subplots(figsize=(10, 6))

categories = ['Issues', 'Pull Requests']
closed_values = [closed_issue_count, closed_pr_count]
open_values = [open_issues, open_prs]

# Create stacked bars
bars1 = ax.bar(categories, closed_values, label='Closed/Resolved', 
               color='#24B064', edgecolor='black', linewidth=1.5)
bars2 = ax.bar(categories, open_values, bottom=closed_values, 
               label='Open/Unresolved', color='#CCCCCC', 
               edgecolor='black', linewidth=1.5)

# Add value labels on each segment
for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
    # Label for closed (bottom segment)
    height1 = bar1.get_height()
    if height1 > 0:
        ax.text(bar1.get_x() + bar1.get_width()/2., height1/2,
                f'{int(height1)}',
                ha='center', va='center', fontweight='bold', fontsize=12, color='white')
    
    # Label for open (top segment)
    height2 = bar2.get_height()
    if height2 > 0:
        ax.text(bar2.get_x() + bar2.get_width()/2., height1 + height2/2,
                f'{int(height2)}',
                ha='center', va='center', fontweight='bold', fontsize=12)
    
    # Total label on top
    total = height1 + height2
    ax.text(bar2.get_x() + bar2.get_width()/2., total,
            f'Total: {int(total)}',
            ha='center', va='bottom', fontweight='bold', fontsize=11)

ax.set_ylabel('Count', fontsize=12)
ax.set_title(f'Issue and PR Activity for {pipeline_name}',
             fontsize=14, fontweight='bold')
ax.grid(True, axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

# Community Metrics

## Active Maintenance Indicators

```{python}
#| label: fig-community-engagement
#| fig-cap: "Community Engagement Metrics"

# Get metrics for the selected pipeline
if pipeline_name != "all" and pipeline_name in pipelines_data['name'].values:
    pipeline_metrics = pipelines_data[pipelines_data['name'] == pipeline_name].iloc[0]
    
    # Create data for bar chart
    metrics = {
        'GitHub Stars': pipeline_metrics['stargazers_count'],
        'Forks': pipeline_metrics['forks_count'],
        'Watchers': pipeline_metrics['watchers_count'],
        'Open Issues': pipeline_metrics['open_issues_count']
    }
    
    # Create bar plot
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(metrics.keys(), metrics.values(), 
                   color=['#24B064', '#1F77B4', '#FFA500', '#DC143C'],
                   edgecolor='black', linewidth=1.5)
    
    # Add value labels on bars
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontweight='bold', fontsize=12)
    
    ax.set_ylabel('Count', fontsize=12)
    ax.set_title(f'Community Engagement Metrics for {pipeline_name}',
                 fontsize=14, fontweight='bold')
    ax.grid(True, axis='y', alpha=0.3)
    plt.tight_layout()
    plt.show()
else:
    print(f"Note: Set pipeline_name to a specific pipeline to see detailed metrics.")
    print(f"Available pipelines: {', '.join(pipelines_data['name'].head(10).tolist())}...")
```

This is a summary of available community engagement statistics.

```{python}
#| output: asis

print(f"""
- **Pipeline:** {pipeline_info['name']}
- **Status:** {pipeline_info['status']}
- **GitHub Stars:** {pipeline_info['stargazers_count']:,}
- **Forks:** {pipeline_info['forks_count']:,}
- **Watchers:** {pipeline_info['watchers_count']:,}
- **Open Issues:** {pipeline_info['open_issues_count']}
- **Last Release:** {pipeline_info['last_release_date'].strftime('%Y-%m-%d') if pd.notna(pipeline_info['last_release_date']) else 'No release yet'}
""")
```

---

# Data Sources and Methodology

## Data Collection

This report aggregates data from multiple sources:

- **GitHub API**: Repository metrics, commits, releases, issues, PRs
- **Pipeline Repositories**: Direct metrics from pipeline codebases
- ...

## Data Status

```{python}
#| output: asis

# Calculate data statistics
#earliest_creation = pipelines_data['gh_created_at'].min()

print(f"""
- **Update Frequency:** Daily (automated pipelines)
- **Data Source:** JSON export from nf-core stats database
""")
```

# Appendix

## Definitions

Not necessarily needed but could be useful.

**Active Pipeline**: Pipeline with at least one release or commit in the last 6 months.

**Maintenance Status**: Pipeline with releases between 6-12 months ago.

**Response Time**: Time from issue/PR creation to first maintainer comment.

**Resolution Time**: Time from issue creation to closure.

**Release Frequency**: Average time between consecutive releases.

## Regulatory Relevance

This report supports regulatory compliance by demonstrating:

1. **Traceability**: Complete version history and change tracking
2. **Quality Control**: Systematic testing and review processes
3. **Maintenance**: Active development and bug resolution
4. **Documentation**: Comprehensive and current documentation
5. **Support**: Responsive community and maintainer support

## Contact and Questions

For questions about this report or the underlying data:

- **nf-core Website**: https://nf-co.re
- **GitHub**: https://github.com/nf-core
- **Slack**: nfcore.slack.com

---

**Report Version:** 1.0.0  
**Generated by:** nf-core stats repository  
**License:** MIT
