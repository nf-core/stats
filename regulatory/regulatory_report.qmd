---
title: "nf-core Pipeline Regulatory Compliance Report"
subtitle: "Quality Metrics and Development Tracking"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    theme: cosmo
    code-fold: show
    code-tools: false
    embed-resources: true
jupyter: python3
execute:
  echo: false
---

```{python}
#| tags: [parameters]
pipeline_name = "rnaseq"
#pipeline_version = 3.0
```

```{python}
#| label: setup
#| include: false

# Import required libraries
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from pathlib import Path
import importlib
import sys
from report_helpers import calculate_status, calculate_trust_score

# Load data from JSON file (nested structure)
with open('data/stats.json', 'r') as f:
    stats_data = json.load(f)

# Convert nested structure to flat dataframe
pipeline_records = []
for pipeline_key, pipeline_data in stats_data.items():
    record = {}
    
    # Extract pipeline_stats
    if 'pipeline_stats' in pipeline_data and pipeline_data['pipeline_stats']:
        record.update(pipeline_data['pipeline_stats'])
    
    # Extract issue_stats
    if 'issue_stats' in pipeline_data and pipeline_data['issue_stats']:
        issue_stats = pipeline_data['issue_stats']
        record['issue_count'] = issue_stats.get('issue_count')
        record['closed_issue_count'] = issue_stats.get('closed_issue_count')
        record['median_seconds_to_issue_closed'] = issue_stats.get('median_seconds_to_issue_closed')
        record['pr_count'] = issue_stats.get('pr_count')
        record['closed_pr_count'] = issue_stats.get('closed_pr_count')
        record['median_seconds_to_pr_closed'] = issue_stats.get('median_seconds_to_pr_closed')
    
    # Extract contributor_stats
    if 'contributor_stats' in pipeline_data and pipeline_data['contributor_stats']:
        record['number_of_contributors'] = pipeline_data['contributor_stats'].get('number_of_contributors')
    
    pipeline_records.append(record)

pipelines_data = pd.DataFrame(pipeline_records)

# Convert date columns to datetime
date_columns = ['last_release_date']
for col in date_columns:
    if col in pipelines_data.columns:
        pipelines_data[col] = pd.to_datetime(pipelines_data[col], utc=True, errors='coerce')

# Add computed columns
pipelines_data['has_release'] = pipelines_data['last_release_date'].notna()

pipelines_data['status'] = pipelines_data.apply(calculate_status, axis=1)

pipelines_data['trust_score'] = pipelines_data.apply(calculate_trust_score, axis=1)

# Filter by pipeline if specified
if pipeline_name != "all":
    pipelines_data = pipelines_data[pipelines_data['name'] == pipeline_name]

if pipeline_name != "all" and pipeline_name in pipelines_data['name'].values:
    pipeline_info = pipelines_data[pipelines_data['name'] == pipeline_name].iloc[0]

# Store for later use
report_date = datetime.now().strftime("%B %d, %Y")
```

```{python}
#| echo: false
#| output: asis

# Format last release date
last_release = pipeline_info['last_release_date'].strftime('%B %d, %Y') if pd.notna(pipeline_info['last_release_date']) else 'No release yet'

print(":::: {.columns}\n")
print("::: {.column width=\"65%\"}\n")

print(f"""| | |
|:---|:---|
| **Pipeline** | {pipeline_name} |
| **Description** | {pipeline_info['description']} |
| **Last Release** | {last_release} |
| **Status** | {pipeline_info['status']} |
| **Report Generated** | {report_date} |
""")

print(":::\n")
print("::: {.column width=\"35%\"}\n")
```

```{python}
#| label: trust-score-gauge
#| fig-width: 5
#| fig-height: 4

# Get the trust score
trust_score = pipeline_info['trust_score']

# Determine color and rating based on score
if trust_score >= 80:
    color = '#24B064'
    rating = 'Excellent'
elif trust_score >= 60:
    color = '#FFA500'
    rating = 'Good'
elif trust_score >= 40:
    color = '#FFD700'
    rating = 'Fair'
else:
    color = '#DC143C'
    rating = 'Needs Improvement'

# Create semi-circular gauge chart
fig, ax = plt.subplots(figsize=(5, 4), subplot_kw={'projection': 'polar'})

# Set up the gauge (semi-circle from 0 to 180 degrees)
theta = np.linspace(0, np.pi, 100)
r = 1

# Background arc (gray)
ax.plot(theta, [r]*len(theta), color='#E8E8E8', linewidth=20, solid_capstyle='round')

# Score arc (colored)
score_theta = np.linspace(0, np.pi * (trust_score / 100), 100)
ax.plot(score_theta, [r]*len(score_theta), color=color, linewidth=20, solid_capstyle='round')

# Add score text in center
ax.text(np.pi/2, 0.3, f'{trust_score}', 
        ha='center', va='center', fontsize=32, fontweight='bold', color=color)
ax.text(np.pi/2, 0.05, rating, 
        ha='center', va='center', fontsize=12, fontweight='bold', color='#333333')

# Add labels at key points
ax.text(0.05, r+0.2, '0', ha='left', va='bottom', fontsize=9, color='#666666')
ax.text(np.pi/4, r+0.15, '25', ha='center', va='bottom', fontsize=9, color='#666666')
ax.text(np.pi/2, r+0.15, '50', ha='center', va='bottom', fontsize=9, color='#666666')
ax.text(3*np.pi/4, r+0.15, '75', ha='center', va='bottom', fontsize=9, color='#666666')
ax.text(np.pi-0.05, r+0.3, '100', ha='right', va='bottom', fontsize=9, color='#666666')

# Style the plot
ax.set_ylim(0, 1.3)
ax.set_theta_offset(np.pi)
ax.set_theta_direction(-1)
ax.set_xticks([])
ax.set_yticks([])
ax.spines['polar'].set_visible(False)
ax.grid(False)
ax.set_title('Trust Score', fontsize=14, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()
```

```{python}
#| echo: false
#| output: asis

print(":::\n")
print("::::\n")
```

::: {.callout-tip icon=false}
## Report Scope

This report provides regulatory-relevant metrics for nf-core pipelines, including:

- Pipeline version control and release history
- Development activity and maintenance status
- Community engagement and support responsiveness
- Quality assurance indicators
- Change management tracking

:::

# Maintenance Metrics

This section tracks the pipeline's ongoing maintenance and support activities, demonstrating active issue resolution and pull request management.

## Issue and PR Resolution Metrics

The following metrics provide insight into the responsiveness and efficiency of the development team in addressing issues and reviewing code contributions.

### Issue Tracking

Issues represent bug reports, feature requests, and general questions from the community. The metrics below show the total number of issues and how effectively they are being resolved.

```{python}
#| label: tbl-issues-summary
#| tbl-cap: "Issues and PR Resolution Metrics"
#| output: asis

# Get issue metrics (handle None values)
issue_count = pipeline_info.get('issue_count', 'N/A')
closed_issue_count = pipeline_info.get('closed_issue_count', 'N/A')
median_issue_close_time = pipeline_info.get('median_seconds_to_issue_closed')
median_issue_days = f"{median_issue_close_time / 86400:.1f}" if pd.notna(median_issue_close_time) else "N/A"

print(f"""
| Metric | Value | Notes |
|--------|-------|-------|
| Issues Count | {issue_count} | Total issues opened |
| Issues Closed | {closed_issue_count} | Issues that have been closed |
| Median Time to Issue Closure | {median_issue_days} days | Time from open to close |
""")
```

### Pull Request Management

Pull requests reflect code contributions from the community and maintainers. These metrics demonstrate the review and integration process efficiency.

```{python}
#| label: tbl-pr-resolution-summary
#| tbl-cap: "Pull Request Resolution Metrics"
#| output: asis

# Get PR metrics (handle None values)
pr_count = pipeline_info.get('pr_count', 'N/A')
closed_pr_count = pipeline_info.get('closed_pr_count', 'N/A')
median_pr_close_time = pipeline_info.get('median_seconds_to_pr_closed')
median_pr_days = f"{median_pr_close_time / 86400:.1f}" if pd.notna(median_pr_close_time) else "N/A"

print(f"""
| Metric | Value | Notes |
|--------|-------|-------|
| Pull Request Count | {pr_count} | Total PRs opened |
| Pull Requests Closed | {closed_pr_count} | PRs that have been merged/closed |
| Median Time to PR Closure | {median_pr_days} days | Time from open to close |
""")
```

```{python}
#| label: fig-issue-pr-metrics
#| fig-cap: "Issue and Pull Request Activity"

# Extract metrics
issue_count = pipeline_info.get('issue_count', 0)
closed_issue_count = pipeline_info.get('closed_issue_count', 0)
pr_count = pipeline_info.get('pr_count', 0)
closed_pr_count = pipeline_info.get('closed_pr_count', 0)

# Handle None values
issue_count = issue_count if pd.notna(issue_count) else 0
closed_issue_count = closed_issue_count if pd.notna(closed_issue_count) else 0
pr_count = pr_count if pd.notna(pr_count) else 0
closed_pr_count = closed_pr_count if pd.notna(closed_pr_count) else 0

# Calculate open (unresolved) counts
open_issues = issue_count - closed_issue_count
open_prs = pr_count - closed_pr_count

# Create stacked bar chart
fig, ax = plt.subplots(figsize=(10, 6))

categories = ['Issues', 'Pull Requests']
closed_values = [closed_issue_count, closed_pr_count]
open_values = [open_issues, open_prs]

# Create stacked bars
bars1 = ax.bar(categories, closed_values, label='Closed/Resolved', 
               color='#24B064', edgecolor='black', linewidth=1.5)
bars2 = ax.bar(categories, open_values, bottom=closed_values, 
               label='Open/Unresolved', color='#CCCCCC', 
               edgecolor='black', linewidth=1.5)

# Add value labels on each segment
for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
    # Label for closed (bottom segment)
    height1 = bar1.get_height()
    height2 = bar2.get_height()
    total = height1 + height2
    
    # Show label inside closed segment if it exists
    if height1 > 0:
        ax.text(bar1.get_x() + bar1.get_width()/2., height1/2,
                f'{int(height1)}',
                ha='center', va='center', fontweight='bold', fontsize=12, color='white')
    
    # Show label inside open segment if it exists
    if height2 > 0:
        ax.text(bar2.get_x() + bar2.get_width()/2., height1 + height2/2,
                f'{int(height2)}',
                ha='center', va='center', fontweight='bold', fontsize=12)
    
    # Total label on top with more spacing
    ax.text(bar2.get_x() + bar2.get_width()/2., total + (max(total * 0.03, 5)),
            f'Total: {int(total)}',
            ha='center', va='bottom', fontweight='bold', fontsize=12)

# Adjust y-axis limits to add space at the top for labels
y_max = max([closed_values[i] + open_values[i] for i in range(len(categories))])
ax.set_ylim(0, y_max * 1.15)  # Add 15% extra space at the top to fit labels

ax.set_ylabel('Count', fontsize=12)
ax.set_title(f'Issue and PR Activity for {pipeline_name}',
             fontsize=14, fontweight='bold')
ax.grid(True, axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

# Community Metrics

This section provides indicators of community health and engagement, demonstrating the pipeline's adoption and active user base.

## Active Maintenance Indicators

Community engagement metrics such as stars, forks, and watchers reflect the pipeline's popularity and adoption within the research community. These indicators help assess the pipeline's impact and sustainability.

```{python}
#| label: fig-community-engagement
#| fig-cap: "Community Engagement Metrics"

# Get metrics for the selected pipeline
if pipeline_name != "all" and pipeline_name in pipelines_data['name'].values:
    pipeline_metrics = pipelines_data[pipelines_data['name'] == pipeline_name].iloc[0]
    
    # Create data for bar chart
    metrics = {
        'GitHub Stars': pipeline_metrics['stargazers_count'],
        'Forks': pipeline_metrics['forks_count'],
        'Watchers': pipeline_metrics['watchers_count'],
        'Open Issues': pipeline_metrics['open_issues_count']
    }
    
    # Create bar plot
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(metrics.keys(), metrics.values(), 
                   color=['#FFA500'],
                   edgecolor='black', linewidth=1.5)
    
    # Add value labels on bars
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontweight='bold', fontsize=12)
    
    ax.set_ylabel('Count', fontsize=12)
    ax.set_title(f'Community Engagement Metrics for {pipeline_name}',
                 fontsize=14, fontweight='bold')
    ax.grid(True, axis='y', alpha=0.3)
    plt.tight_layout()
    plt.show()
else:
    print(f"Note: Set pipeline_name to a specific pipeline to see detailed metrics.")
    print(f"Available pipelines: {', '.join(pipelines_data['name'].head(10).tolist())}...")
```

This is a summary of available community engagement statistics.

```{python}
#| output: asis

print(f"""
- **Pipeline:** {pipeline_info['name']}
- **Status:** {pipeline_info['status']}
- **GitHub Stars:** {pipeline_info['stargazers_count']:,}
- **Forks:** {pipeline_info['forks_count']:,}
- **Watchers:** {pipeline_info['watchers_count']:,}
- **Open Issues:** {pipeline_info['open_issues_count']}
- **Last Release:** {pipeline_info['last_release_date'].strftime('%Y-%m-%d') if pd.notna(pipeline_info['last_release_date']) else 'No release yet'}
""")
```

---

# Data Sources and Methodology

This section documents the data sources and collection methods used to generate this report, ensuring transparency and reproducibility.

## Data Collection

This report aggregates data from multiple sources:

- **GitHub API**: Repository metrics, commits, releases, issues, PRs
- **Pipeline Repositories**: Direct metrics from pipeline codebases
- ...

## Data Status

Information about data currency and update frequency:

```{python}
#| output: asis

# Calculate data statistics
#earliest_creation = pipelines_data['gh_created_at'].min()

print(f"""
- **Update Frequency:** Daily (automated pipelines)
- **Data Source:** JSON export from nf-core stats database
""")
```

# Appendix

::: {.callout-tip icon=false}
## Definitions

Key terms and metrics used throughout this report:

**Active Pipeline**: Pipeline with at least one release or commit in the last 6 months.

**Maintenance Status**: Pipeline with releases between 6-12 months ago.

**Response Time**: Time from issue/PR creation to first maintainer comment.

**Resolution Time**: Time from issue creation to closure.

**Release Frequency**: Average time between consecutive releases.
:::

::: {.callout-important icon=false}
## Regulatory Relevance

This section explains how the metrics in this report support regulatory compliance requirements:

This report supports regulatory compliance by demonstrating:

1. **Traceability**: Complete version history and change tracking
2. **Quality Control**: Systematic testing and review processes
3. **Maintenance**: Active development and bug resolution
4. **Documentation**: Comprehensive and current documentation
5. **Support**: Responsive community and maintainer support
:::

::: {.callout-note icon=false}
## Contact and Questions

For additional information or questions regarding this report:

For questions about this report or the underlying data:

- **nf-core Website**: https://nf-co.re
- **GitHub**: https://github.com/nf-core
- **Slack**: nfcore.slack.com
:::

---

**Report Version:** 1.0.0  
**Generated by:** nf-core stats repository  
**License:** MIT
